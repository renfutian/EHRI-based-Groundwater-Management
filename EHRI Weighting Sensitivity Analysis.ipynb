{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ffadc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall τ 与基准比较\n",
      "  ReCiPe   : 0.932\n",
      "  +20 % w_HH: 0.913\n",
      "  –20 % w_HH: 0.899\n",
      "\n",
      "Rank-shift summary\n",
      "     Scenario  Kendall_tau_vs_base  Material_rank_shift\n",
      "0      ReCiPe             0.931746                 True\n",
      "1  +20 % w_HH             0.912568                 True\n",
      "2  –20 % w_HH             0.898661                 True\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 1. 读入数据 (Read data)\n",
    "# --------------------------\n",
    "# 修改为你的文件路径/工作表名称 (Modify to your file path/sheet name)\n",
    "df = pd.read_excel(\"367EHRI Sensitivity Analysis.xlsx\", sheet_name='Sheet1')\n",
    "\n",
    "# --------------------------\n",
    "# 2. 计算人体健康端点 P_HH (Calculate human health endpoint P_HH)\n",
    "# --------------------------\n",
    "# df[\"P_HH\"] = np.maximum(df[\"P_C\"], df[\"P_NC\"])\n",
    "\n",
    "# --------------------------\n",
    "# 3. 定义 TEHR 计算函数 (Define TEHR calculation function)\n",
    "# --------------------------\n",
    "def calc_tehr(df, w_eco: float, w_hh: float, col_name: str) -> None:\n",
    "    \"\"\"向 DataFrame 添加一列 TEHR = w_eco*P_E + w_hh*P_HH\"\"\"\n",
    "    \"\"\"Add a column TEHR = w_eco*P_E + w_hh*P_HH to DataFrame\"\"\"\n",
    "    df[col_name] = w_eco * df[\"ERA_Max\"] + w_hh * df[\"HHRA_Max\"]\n",
    "\n",
    "# (i) 基准权重 0.42 : 0.58（UNEP-GLAM）((i) Baseline weights 0.42 : 0.58 (UNEP-GLAM))\n",
    "w_hh_base = 0.58\n",
    "calc_tehr(df, w_eco=1 - w_hh_base, w_hh=w_hh_base, col_name=\"TEHR_base\")\n",
    "\n",
    "# (ii) ReCiPe 40 / 40（→ 0.50 / 0.50）((ii) ReCiPe 40 / 40 (→ 0.50 / 0.50))\n",
    "calc_tehr(df, w_eco=0.50, w_hh=0.50, col_name=\"TEHR_recipe\")\n",
    "\n",
    "# (iii) ±20 % 敏感性分析（保持 w_eco + w_hh = 1）((iii) ±20 % sensitivity analysis (maintain w_eco + w_hh = 1))\n",
    "w_hh_up   = min(1.0, w_hh_base * 1.20)\n",
    "w_hh_down = w_hh_base * 0.80\n",
    "calc_tehr(df, w_eco=1 - w_hh_up,   w_hh=w_hh_up,   col_name=\"TEHR_up20\")\n",
    "calc_tehr(df, w_eco=1 - w_hh_down, w_hh=w_hh_down, col_name=\"TEHR_down20\")\n",
    "\n",
    "# --------------------------\n",
    "# 4. 排名与 Kendall-τ 比较 (Ranking and Kendall-τ comparison)\n",
    "# --------------------------\n",
    "def kendall_tau(a, b):\n",
    "    \"\"\"返回 Kendall τ 相关系数（忽略 NA）\"\"\"\n",
    "    \"\"\"Return Kendall τ correlation coefficient (ignoring NA)\"\"\"\n",
    "    return kendalltau(a, b, nan_policy=\"omit\").correlation\n",
    "\n",
    "rank_cols = [\"TEHR_base\", \"TEHR_recipe\", \"TEHR_up20\", \"TEHR_down20\"]\n",
    "# 将得分越大排名越靠前（ascending=False）(Higher scores rank higher (ascending=False))\n",
    "ranks = df[rank_cols].rank(ascending=False, method=\"min\")\n",
    "\n",
    "tau_recipe = kendall_tau(ranks[\"TEHR_base\"], ranks[\"TEHR_recipe\"])\n",
    "tau_up20   = kendall_tau(ranks[\"TEHR_base\"], ranks[\"TEHR_up20\"])\n",
    "tau_down20 = kendall_tau(ranks[\"TEHR_base\"], ranks[\"TEHR_down20\"])\n",
    "\n",
    "print(\"Kendall τ 与基准比较\")  # (Kendall τ compared to baseline)\n",
    "print(f\"  ReCiPe   : {tau_recipe:.3f}\")\n",
    "print(f\"  +20 % w_HH: {tau_up20:.3f}\")\n",
    "print(f\"  –20 % w_HH: {tau_down20:.3f}\")\n",
    "\n",
    "# --------------------------\n",
    "# 5. 输出结果 (Output results)\n",
    "# --------------------------\n",
    "# 结果汇总表 (Results summary table)\n",
    "summary = pd.DataFrame({\n",
    "    \"Scenario\": [\"ReCiPe\", \"+20 % w_HH\", \"–20 % w_HH\"],\n",
    "    \"Kendall_tau_vs_base\": [tau_recipe, tau_up20, tau_down20],\n",
    "    \"Material_rank_shift\": [abs(1 - tau_recipe) > 0.05,\n",
    "                            abs(1 - tau_up20)   > 0.05,\n",
    "                            abs(1 - tau_down20) > 0.05]\n",
    "})\n",
    "print(\"\\nRank-shift summary\")  # (排名变化摘要)\n",
    "print(summary)\n",
    "\n",
    "# 保存带有全部 TEHR 分数和排名的 Excel (Save Excel with all TEHR scores and ranks)\n",
    "df_out = pd.concat([df, ranks.add_suffix(\"_rank\")], axis=1)\n",
    "df_out.to_excel(\"tehr_results.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall τ 与基准比较 (固定权重)\n",
      "EHRI_recipe : 0.932\n",
      "EHRI_up20   : 0.913\n",
      "EHRI_down20 : 0.899\n",
      "\n",
      "Monte‑Carlo sensitivity (w_HH ±20 %, n=1000)\n",
      "tau_mean            : 0.952\n",
      "tau_median          : 0.950\n",
      "tau_min             : 0.899\n",
      "EHRI>0.55           : 339.558\n",
      "EHRI>0.60           : 333.193\n",
      "EHRI>0.65           : 330.582\n",
      "tau_max             : 1.000\n",
      "tau_2.5pct          : 0.904\n",
      "tau_97.5pct         : 0.998\n",
      "prop_material_shift : 0.498\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 参数区 (Parameter section)\n",
    "EXCEL_FILE = \"367EHRI Sensitivity Analysis.xlsx\"   # 输入文件 (Input file)\n",
    "SHEET_NAME = 'Sheet1'                 # 工作表索引/名称 (Worksheet index/name)\n",
    "N_SIM = 1000                    # Monte‑Carlo 迭代次数 (Monte Carlo iterations)\n",
    "W_HH_BASE = 0.58                # 基准人体健康权重 (UNEP‑GLAM) (Baseline human health weight (UNEP-GLAM))\n",
    "PERTURB_FRAC = 0.20             # 浮动幅度 ±20 % (Perturbation magnitude ±20%)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 1. 读取数据 (Read data) -----------------------------------------------------------\n",
    "df = pd.read_excel(EXCEL_FILE, sheet_name=SHEET_NAME)\n",
    "\n",
    "# # 2. 计算保守人体健康概率 (Calculate conservative human health probability) ---------------------------------------------\n",
    "# df[\"P_HH\"] = np.maximum(df[\"P_C\"], df[\"P_NC\"])\n",
    "\n",
    "# 3. 辅助函数：计算并附加 EHRI 列 (Helper function: calculate and append EHRI column) -------------------------------------\n",
    "\n",
    "def add_tehr(df, w_eco: float, w_hh: float, col: str) -> None:\n",
    "    df[col] = w_eco * df[\"ERA_Max\"] + w_hh * df[\"HHRA_Max\"]\n",
    "\n",
    "# 3a. 基准 TEHRI (0.42 / 0.58) (Baseline TEHRI (0.42 / 0.58))\n",
    "add_tehr(df, 1 - W_HH_BASE, W_HH_BASE, \"EHRI_base\")\n",
    "\n",
    "# 3b. ReCiPe 等权 0.50 / 0.50 (ReCiPe equal weights 0.50 / 0.50)\n",
    "add_tehr(df, 0.50, 0.50, \"EHRI_recipe\")\n",
    "\n",
    "# 3c. 固定 ±20 % 敏感性场景 (Fixed ±20% sensitivity scenarios)\n",
    "w_hh_low, w_hh_high = W_HH_BASE * (1 - PERTURB_FRAC), W_HH_BASE * (1 + PERTURB_FRAC)\n",
    "add_tehr(df, 1 - w_hh_low,  w_hh_low,  \"EHRI_down20\")\n",
    "add_tehr(df, 1 - w_hh_high, w_hh_high, \"EHRI_up20\")\n",
    "\n",
    "# 4. 排名与 Kendall‑τ (固定场景) (Ranking and Kendall-τ (fixed scenarios)) --------------------------------------\n",
    "\n",
    "def kendall_tau(series_a, series_b):\n",
    "    return kendalltau(series_a, series_b, nan_policy=\"omit\").correlation\n",
    "\n",
    "rank_cols = [\"EHRI_base\", \"EHRI_recipe\", \"EHRI_up20\", \"EHRI_down20\"]\n",
    "ranks_fixed = df[rank_cols].rank(ascending=False, method=\"min\")\n",
    "\n",
    "print(\"Kendall τ 与基准比较 (固定权重)\")  # (Kendall τ compared to baseline (fixed weights))\n",
    "for col in rank_cols[1:]:\n",
    "    tau_val = kendall_tau(ranks_fixed[\"EHRI_base\"], ranks_fixed[col])\n",
    "    print(f\"{col:12s}: {tau_val:.3f}\")\n",
    "\n",
    "tau_mc = []\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# 添加额外权重场景 (Add additional weight scenarios)\n",
    "add_tehr(df, 1 - 0.65,  0.65,  \"EHRI_065\")\n",
    "ranks_fixed_065 = df['EHRI_065'].rank(ascending=False, method=\"min\")\n",
    "add_tehr(df, 1 - 0.6,  0.6,  \"EHRI_06\")\n",
    "ranks_fixed_06 = df['EHRI_06'].rank(ascending=False, method=\"min\")\n",
    "add_tehr(df, 1 - 0.55,  0.55,  \"EHRI_055\")\n",
    "ranks_fixed_055 = df['EHRI_055'].rank(ascending=False, method=\"min\")\n",
    "num065 = []\n",
    "num06 = []\n",
    "num055 = []\n",
    "\n",
    "tehr_sim_sum = []\n",
    "for w_hh in rng.uniform(low=w_hh_low, high=w_hh_high, size=N_SIM):\n",
    "    tehr_sim = (1 - w_hh) * df[\"ERA_Max\"] + w_hh * df[\"HHRA_Max\"]\n",
    "    tehr_sim_sum.append(tehr_sim)\n",
    "    rank_sim = tehr_sim.rank(ascending=False, method=\"min\")\n",
    "    tau_mc.append(kendall_tau(ranks_fixed[\"EHRI_base\"], rank_sim))\n",
    "\n",
    "    # 计算大于特定阈值的数量 (Calculate count above specific thresholds)\n",
    "    gt065 = np.sum(tehr_sim > 0.65)\n",
    "    gt06 = np.sum(tehr_sim > 0.6)\n",
    "    gt055 = np.sum(tehr_sim > 0.55)\n",
    "    num065.append(kendall_tau(ranks_fixed_065, rank_sim))\n",
    "    num06.append(kendall_tau(ranks_fixed_06, rank_sim))\n",
    "    num055.append(kendall_tau(ranks_fixed_055, rank_sim))\n",
    "\n",
    "tau_mc = np.asarray(tau_mc)\n",
    "tehr_sim_sum = np.asarray(tehr_sim_sum)\n",
    "\n",
    "num065 = np.asarray(num065)\n",
    "num06 = np.asarray(num06)\n",
    "num055 = np.asarray(num055)\n",
    "\n",
    "# 6. Monte‑Carlo 结果汇总 (Monte Carlo results summary) ---------------------------------------------\n",
    "summary_mc = {\n",
    "    \"N_sim\": N_SIM,\n",
    "    \"tau_mean\": tau_mc.mean(),  # Kendall τ 平均值 (Kendall τ mean)\n",
    "    \"tau_median\": np.median(tau_mc),  # Kendall τ 中位数 (Kendall τ median)\n",
    "    \"tau_min\": tau_mc.min(),  # Kendall τ 最小值 (Kendall τ minimum)\n",
    "    \"EHRI>0.55\": np.sum(tehr_sim_sum > 0.55) / N_SIM,  # EHRI 大于 0.55 的比例 (Proportion of EHRI > 0.55)\n",
    "    \"EHRI>0.60\": np.sum(tehr_sim_sum > 0.60) / N_SIM,  # EHRI 大于 0.60 的比例 (Proportion of EHRI > 0.60)\n",
    "    \"EHRI>0.65\": np.sum(tehr_sim_sum > 0.65) / N_SIM,  # EHRI 大于 0.65 的比例 (Proportion of EHRI > 0.65)\n",
    "    \"tau_max\": tau_mc.max(),  # Kendall τ 最大值 (Kendall τ maximum)\n",
    "    \"tau_2.5pct\": np.percentile(tau_mc, 2.5),  # 2.5% 分位数 (2.5% percentile)\n",
    "    \"tau_97.5pct\": np.percentile(tau_mc, 97.5),  # 97.5% 分位数 (97.5% percentile)\n",
    "    \"prop_material_shift\": np.mean(np.abs(1 - tau_mc) > 0.05)  # 材料排名变化比例 (Proportion of material rank shifts)\n",
    "}\n",
    "\n",
    "print(f\"\\nMonte‑Carlo sensitivity (w_HH ±{PERTURB_FRAC*100:.0f} %, n={N_SIM})\")  # (蒙特卡洛敏感性分析)\n",
    "for k, v in summary_mc.items():\n",
    "    if k != \"N_sim\":\n",
    "        print(f\"{k:20s}: {v:.3f}\")\n",
    "\n",
    "# 7. 导出结果 (Export results) ------------------------------------------------------------\n",
    "# 保存固定权重排名 (Save fixed weight ranks)\n",
    "ranks_fixed.add_suffix(\"_rank\").to_excel(\"EHRI_fixed_ranks.xlsx\", index=False)\n",
    "# 保存 τ 分布 (Save τ distribution)\n",
    "pd.DataFrame({\"tau\": tau_mc}).to_csv(\"tau_distribution.csv\", index=False)\n",
    "# 保存 τ 摘要 (Save τ summary)\n",
    "pd.DataFrame(summary_mc, index=[0]).to_excel(\"tau_summary.xlsx\", index=False)\n",
    "\n",
    "# 保存大于阈值的数量 (Save counts above thresholds)\n",
    "pd.DataFrame({\n",
    "    \"num065\": num065, \n",
    "    \"num06\": num06, \n",
    "    \"num055\": num055 \n",
    "}).to_csv(\"gt_num.csv\", index=False)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 参数区\n",
    "EXCEL_FILE = \"367EHRI Sensitivity Analysis.xlsx\"   # 输入文件\n",
    "SHEET_NAME = 'Sheet1'                 # 工作表索引/名称\n",
    "N_SIM = 1000                    # Monte‑Carlo 迭代次数\n",
    "W_HH_BASE = 0.58                # 基准人体健康权重 (UNEP‑GLAM)\n",
    "PERTURB_FRAC = 0.20             # 浮动幅度 ±20 %\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 1. 读取数据 -----------------------------------------------------------\n",
    "df = pd.read_excel(EXCEL_FILE, sheet_name=SHEET_NAME)\n",
    "\n",
    "# # 2. 计算保守人体健康概率 ---------------------------------------------\n",
    "# df[\"P_HH\"] = np.maximum(df[\"P_C\"], df[\"P_NC\"])\n",
    "\n",
    "# 3. 辅助函数：计算并附加 EHRI 列 -------------------------------------\n",
    "\n",
    "def add_tehr(df, w_eco: float, w_hh: float, col: str) -> None:\n",
    "    df[col] = w_eco * df[\"ERA_Max\"] + w_hh * df[\"HHRA_Max\"]\n",
    "\n",
    "# 3a. 基准 TEHRI (0.42 / 0.58)\n",
    "add_tehr(df, 1 - W_HH_BASE, W_HH_BASE, \"EHRI_base\")\n",
    "\n",
    "# 3b. ReCiPe 等权 0.50 / 0.50\n",
    "add_tehr(df, 0.50, 0.50, \"EHRI_recipe\")\n",
    "\n",
    "# 3c. 固定 ±20 % 敏感性场景\n",
    "w_hh_low, w_hh_high = W_HH_BASE * (1 - PERTURB_FRAC), W_HH_BASE * (1 + PERTURB_FRAC)\n",
    "add_tehr(df, 1 - w_hh_low,  w_hh_low,  \"EHRI_down20\")\n",
    "add_tehr(df, 1 - w_hh_high, w_hh_high, \"EHRI_up20\")\n",
    "\n",
    "\n",
    "# 4. 排名与 Kendall‑τ (固定场景) --------------------------------------\n",
    "\n",
    "def kendall_tau(series_a, series_b):\n",
    "    return kendalltau(series_a, series_b, nan_policy=\"omit\").correlation\n",
    "\n",
    "rank_cols = [\"EHRI_base\", \"EHRI_recipe\", \"EHRI_up20\", \"EHRI_down20\"]\n",
    "ranks_fixed = df[rank_cols].rank(ascending=False, method=\"min\")\n",
    "\n",
    "print(\"Kendall τ 与基准比较 (固定权重)\")\n",
    "for col in rank_cols[1:]:\n",
    "    tau_val = kendall_tau(ranks_fixed[\"EHRI_base\"], ranks_fixed[col])\n",
    "    print(f\"{col:12s}: {tau_val:.3f}\")\n",
    "\n",
    "tau_mc = []\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# \n",
    "add_tehr(df, 1 - 0.65,  0.65,  \"EHRI_065\")\n",
    "ranks_fixed_065 = df['EHRI_065'].rank(ascending=False, method=\"min\")\n",
    "add_tehr(df, 1 - 0.6,  0.6,  \"EHRI_06\")\n",
    "ranks_fixed_06 = df['EHRI_06'].rank(ascending=False, method=\"min\")\n",
    "add_tehr(df, 1 - 0.55,  0.55,  \"EHRI_055\")\n",
    "ranks_fixed_055 = df['EHRI_055'].rank(ascending=False, method=\"min\")\n",
    "num065 = []\n",
    "num06 = []\n",
    "num055 = []\n",
    "\n",
    "tehr_sim_sum = []\n",
    "for w_hh in rng.uniform(low=w_hh_low, high=w_hh_high, size=N_SIM):\n",
    "    tehr_sim = (1 - w_hh) * df[\"ERA_Max\"] + w_hh * df[\"HHRA_Max\"]\n",
    "    tehr_sim_sum.append(tehr_sim)\n",
    "    rank_sim = tehr_sim.rank(ascending=False, method=\"min\")\n",
    "    tau_mc.append(kendall_tau(ranks_fixed[\"EHRI_base\"], rank_sim))\n",
    "\n",
    "    # \n",
    "    # print('tehr_sim', tehr_sim)\n",
    "    gt065 = np.sum(tehr_sim > 0.65)\n",
    "    gt06 = np.sum(tehr_sim > 0.6)\n",
    "    gt055 = np.sum(tehr_sim > 0.55)\n",
    "    # gt055 = np.sum(tehr_sim < df[\"EHRI_055_045\"])\n",
    "    num065.append(kendall_tau(ranks_fixed_065, rank_sim))\n",
    "    num06.append(kendall_tau(ranks_fixed_06, rank_sim))\n",
    "    num055.append(kendall_tau(ranks_fixed_055, rank_sim))\n",
    "\n",
    "\n",
    "tau_mc = np.asarray(tau_mc)\n",
    "tehr_sim_sum = np.asarray(tehr_sim_sum)\n",
    "\n",
    "num065 = np.asarray(num065)\n",
    "num06 = np.asarray(num06)\n",
    "num055 = np.asarray(num055)\n",
    "\n",
    "\n",
    "# 6. Monte‑Carlo 结果汇总 ---------------------------------------------\n",
    "summary_mc = {\n",
    "    \"N_sim\": N_SIM,\n",
    "    \"tau_mean\": tau_mc.mean(),\n",
    "    \"tau_median\": np.median(tau_mc),\n",
    "    \"tau_min\": tau_mc.min(),\n",
    "    \"EHRI>0.55\": np.sum(tehr_sim_sum > 0.55) / N_SIM,\n",
    "    \"EHRI>0.60\": np.sum(tehr_sim_sum > 0.60) / N_SIM,\n",
    "    \"EHRI>0.65\": np.sum(tehr_sim_sum > 0.65) / N_SIM,\n",
    "    \"tau_max\": tau_mc.max(),\n",
    "    \"tau_2.5pct\": np.percentile(tau_mc, 2.5),\n",
    "    \"tau_97.5pct\": np.percentile(tau_mc, 97.5),\n",
    "    \"prop_material_shift\": np.mean(np.abs(1 - tau_mc) > 0.05)\n",
    "}\n",
    "\n",
    "print(f\"\\nMonte‑Carlo sensitivity (w_HH ±{PERTURB_FRAC*100:.0f} %, n={N_SIM})\")\n",
    "for k, v in summary_mc.items():\n",
    "    if k != \"N_sim\":\n",
    "        print(f\"{k:20s}: {v:.3f}\")\n",
    "\n",
    "# 7. 导出结果 ------------------------------------------------------------\n",
    "ranks_fixed.add_suffix(\"_rank\").to_excel(\"EHRI_fixed_ranks.xlsx\", index=False)\n",
    "pd.DataFrame({\"tau\": tau_mc}).to_csv(\"tau_distribution.csv\", index=False)\n",
    "pd.DataFrame(summary_mc, index=[0]).to_excel(\"tau_summary.xlsx\", index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"num065\": num065, \n",
    "    \"num06\": num06, \n",
    "    \"num055\": num055 \n",
    "}).to_csv(\"gt_num.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
