{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27289fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "\n",
    "file_root_dir = os.path.dirname(os.path.realpath('__file__'))  # .ipynb\n",
    "\n",
    "mec_file_path = os.path.join(file_root_dir, 'data', 'MEC.xlsx')\n",
    "ra_rer_file_path = os.path.join(file_root_dir, 'data', 'RA+RER.xlsx')\n",
    "ca_rer_file_path = os.path.join(file_root_dir, 'data', 'CA+RER.xlsx')\n",
    "\n",
    "mec_data = pd.read_excel(mec_file_path)\n",
    "ra_rer_data = pd.read_excel(ra_rer_file_path)\n",
    "ca_rer_data = pd.read_excel(ca_rer_file_path)\n",
    "# print(mec_data)\n",
    "# print(ra_rer_data)\n",
    "# print(ca_rer_data)\n",
    "print(mec_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class\n",
    "class_types = [\n",
    "    'Inorganic compounds', \n",
    "    'Metals', \n",
    "    'Haloalkanes', \n",
    "    'PAHs', \n",
    "    'Pesticides', \n",
    "    'OCPs', \n",
    "    'Phenols', \n",
    "    'Chlorobenzenes', \n",
    "    'BTEXs', \n",
    "    'Nitrobenzenes', \n",
    "    'Esters', \n",
    "    'Ethers', \n",
    "    'Ketones', \n",
    "    'Aldehydes', \n",
    "    'Anilines', \n",
    "    'Amides', \n",
    "    'Nitrosamines', \n",
    "    'PCBs', \n",
    "    'Others', \n",
    "    'PAEs', \n",
    "    'PFCAs', \n",
    "    'PFSAs', \n",
    "]\n",
    "\n",
    "# Point\n",
    "points = list(dict.fromkeys(mec_data.loc[:, 'Point'].values))\n",
    "\n",
    "# # RA + RER\n",
    "msPAF_set = []\n",
    "points_set = []\n",
    "classes_set = []\n",
    "\n",
    "points_all_set = []\n",
    "msPAFmix_all_set = []\n",
    "\n",
    "for point in points:\n",
    "    print(point)\n",
    "    paf_1_prod_set = []\n",
    "    for class_type in class_types:\n",
    "        # filter\n",
    "        mec_filter = mec_data[(mec_data['Class'] == class_type) & (mec_data['Point'] == point)]\n",
    "        ra_rer_filter = ra_rer_data[ra_rer_data['Class'] == class_type]\n",
    "        # extract\n",
    "        mec = mec_filter.loc[:, 'Concentration(ug/L)'].values\n",
    "        mec_log = np.log10(mec / 1000)\n",
    "        mu = ra_rer_filter.loc[:, '均值（μ）\\nLOG'].values\n",
    "        sigma = ra_rer_filter.loc[:, '样本标准差（σ）\\nLOG'].values\n",
    "        o11 = ra_rer_filter.loc[:, ' Detection rate\\n(O11)'].values\n",
    "        o12 = ra_rer_filter.loc[:, 'Exceedance rate\\n(O12)'].values\n",
    "        # cal\n",
    "        z = (mec_log - mu) / sigma\n",
    "        paf = norm.cdf(z, loc=mu, scale=sigma) * o11 * o12\n",
    "        paf[np.isnan(paf)] = 0\n",
    "        paf_1 = 1 - paf\n",
    "        \n",
    "        # 1- each class\n",
    "        msPAF = np.prod(paf_1)\n",
    "\n",
    "        # 存储\n",
    "        paf_1_prod_set.append(np.prod(paf_1))  # mix\n",
    "        msPAF_set.append(msPAF)\n",
    "        points_set.append(point)\n",
    "        classes_set.append(class_type)\n",
    "    # 2- all class\n",
    "    msPAFmix_all_set.append(np.prod(paf_1_prod_set))\n",
    "    points_all_set.append(point)\n",
    "# 1-\n",
    "risk_RA_single = pd.DataFrame(\n",
    "    np.column_stack([\n",
    "        points_set, classes_set, msPAF_set, 1-np.array(msPAF_set)\n",
    "    ]), \n",
    "    columns=[\n",
    "        'Point', 'Class', 'msPAF', '1-msPAF_set'\n",
    "    ]\n",
    ")\n",
    "risk_RA_single.to_excel(f'RA+RER_single.xlsx')\n",
    "# 2-\n",
    "risk_RA_all = pd.DataFrame(\n",
    "    np.column_stack([\n",
    "        points_all_set, msPAFmix_all_set, 1-np.array(msPAFmix_all_set)\n",
    "    ]), \n",
    "    columns=[\n",
    "        'Point', 'msPAFmix', '1-msPAFmix_all_set'\n",
    "    ]\n",
    ")\n",
    "risk_RA_all.to_excel(f'RA+RER_all.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CA + RER\n",
    "msPAFCA_set = []\n",
    "points_set = []\n",
    "classes_set = []\n",
    "\n",
    "points_all_set = []\n",
    "msPAFmix_all_set = []\n",
    "\n",
    "for point in points:\n",
    "    print(point)\n",
    "    \n",
    "    hu_sum_set = []\n",
    "    sigma_set = []\n",
    "    \n",
    "    for class_type in class_types:\n",
    "        # filter\n",
    "        mec_filter = mec_data[(mec_data['Class'] == class_type) & (mec_data['Point'] == point)]\n",
    "        ca_rer_filter = ca_rer_data[ca_rer_data['Class'] == class_type]\n",
    "        # extract\n",
    "        \n",
    "        mec = mec_filter.loc[:, 'Concentration(ug/L)'].values\n",
    "        x = ca_rer_filter.loc[:, '几何均值\\nx\\nmg/L'].values\n",
    "        sigma = ca_rer_filter.loc[:, '方差（σ）\\nLOG'].values\n",
    "        o11 = ca_rer_filter.loc[:, ' Detection rate\\n(O11)'].values\n",
    "        o12 = ca_rer_filter.loc[:, 'Exceedance rate\\n(O12)'].values\n",
    "        # cal\n",
    "        hu = mec / 1000 / x\n",
    "        hu = hu * o11 * o12\n",
    "        # hu[np.isnan(hu)] = 0\n",
    "\n",
    "        \n",
    "        mask = ~np.isnan(sigma) & ~np.isnan(hu)\n",
    "        hu = hu[mask]\n",
    "        sigma = sigma[mask]\n",
    "        \n",
    "        sigma_avg = np.mean(sigma)\n",
    "        hu_sum = np.sum(hu)\n",
    "        t = np.log10(hu_sum)\n",
    "        t = 0 if np.isinf(t) else t\n",
    "        \n",
    "        # 1- each class\n",
    "        msPAFCA = norm.cdf(t, loc=0, scale=sigma_avg)\n",
    "        msPAFCA = 0 if t == 0 else msPAFCA\n",
    "        \n",
    "        # 存储\n",
    "        hu_sum_set.append(hu_sum)  # mix\n",
    "        sigma_set.append(sigma)  # mix\n",
    "        msPAFCA_set.append(msPAFCA)\n",
    "        points_set.append(point)\n",
    "        classes_set.append(class_type)\n",
    "\n",
    "    # 2-all class\n",
    "    hu_sum_all = np.sum(hu_sum_set)\n",
    "    t_all = np.log(hu_sum_all)\n",
    "    sigma_avg_all = np.mean(np.concatenate([arr.ravel() for arr in sigma_set]))\n",
    "    msPAFCAmix = norm.cdf(t_all, loc=0, scale=sigma_avg_all)\n",
    "    \n",
    "    points_all_set.append(point)\n",
    "    msPAFmix_all_set.append(msPAFCAmix)\n",
    "\n",
    "# 1-\n",
    "risk_CA_single = pd.DataFrame(\n",
    "    np.column_stack([\n",
    "        points_set, classes_set, msPAFCA_set\n",
    "    ]), \n",
    "    columns=[\n",
    "        'Point', 'Class', 'msPAF'\n",
    "    ]\n",
    ")\n",
    "risk_CA_single.to_excel(f'CA+RER_single.xlsx')\n",
    "# 2-\n",
    "risk_CA_all = pd.DataFrame(\n",
    "    np.column_stack([\n",
    "        points_all_set, msPAFmix_all_set\n",
    "    ]), \n",
    "    columns=[\n",
    "        'Point', 'msPAFmix'\n",
    "    ]\n",
    ")\n",
    "risk_CA_all.to_excel(f'CA+RER_all.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034a647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
